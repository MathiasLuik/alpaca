{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.mlp import MLP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = torchvision.datasets.MNIST(root='../../data', train=True, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size):\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root='../../data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root='../../data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "device = ('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "num_epochs = 10\n",
    "layers = [784, 100, 10]\n",
    "\n",
    "train_loader, test_loader = get_data(batch_size=64)\n",
    "model = MLP(layers).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n",
      "Epoch [1/10], Step [100], Loss: 2.1869\n",
      "Epoch [1/10], Step [200], Loss: 2.1390\n",
      "Epoch [1/10], Step [300], Loss: 2.0658\n",
      "Epoch [1/10], Step [400], Loss: 1.9261\n",
      "Epoch [1/10], Step [500], Loss: 1.8008\n",
      "Epoch [1/10], Step [600], Loss: 1.8224\n",
      "Epoch [1/10], Step [700], Loss: 1.8942\n",
      "Epoch [1/10], Step [800], Loss: 1.8212\n",
      "Epoch [1/10], Step [900], Loss: 1.7868\n",
      "Epoch [2/10], Step [100], Loss: 1.7156\n",
      "Epoch [2/10], Step [200], Loss: 1.5007\n",
      "Epoch [2/10], Step [300], Loss: 1.6980\n",
      "Epoch [2/10], Step [400], Loss: 1.5911\n",
      "Epoch [2/10], Step [500], Loss: 1.4862\n",
      "Epoch [2/10], Step [600], Loss: 1.7308\n",
      "Epoch [2/10], Step [700], Loss: 1.4886\n",
      "Epoch [2/10], Step [800], Loss: 1.5422\n",
      "Epoch [2/10], Step [900], Loss: 1.6393\n",
      "Epoch [3/10], Step [100], Loss: 1.5698\n",
      "Epoch [3/10], Step [200], Loss: 1.7007\n",
      "Epoch [3/10], Step [300], Loss: 1.5270\n",
      "Epoch [3/10], Step [400], Loss: 1.4855\n",
      "Epoch [3/10], Step [500], Loss: 1.4380\n",
      "Epoch [3/10], Step [600], Loss: 1.3663\n",
      "Epoch [3/10], Step [700], Loss: 1.6103\n",
      "Epoch [3/10], Step [800], Loss: 1.4179\n",
      "Epoch [3/10], Step [900], Loss: 1.4416\n",
      "Epoch [4/10], Step [100], Loss: 1.6479\n",
      "Epoch [4/10], Step [200], Loss: 1.3701\n",
      "Epoch [4/10], Step [300], Loss: 1.1604\n",
      "Epoch [4/10], Step [400], Loss: 1.3253\n",
      "Epoch [4/10], Step [500], Loss: 1.2876\n",
      "Epoch [4/10], Step [600], Loss: 1.4719\n",
      "Epoch [4/10], Step [700], Loss: 1.3413\n",
      "Epoch [4/10], Step [800], Loss: 1.1467\n",
      "Epoch [4/10], Step [900], Loss: 1.4931\n",
      "Epoch [5/10], Step [100], Loss: 1.2042\n",
      "Epoch [5/10], Step [200], Loss: 1.3489\n",
      "Epoch [5/10], Step [300], Loss: 1.2645\n",
      "Epoch [5/10], Step [400], Loss: 1.2403\n",
      "Epoch [5/10], Step [500], Loss: 1.3602\n",
      "Epoch [5/10], Step [600], Loss: 1.0975\n",
      "Epoch [5/10], Step [700], Loss: 1.4107\n",
      "Epoch [5/10], Step [800], Loss: 1.2887\n",
      "Epoch [5/10], Step [900], Loss: 1.1816\n",
      "Epoch [6/10], Step [100], Loss: 1.4132\n",
      "Epoch [6/10], Step [200], Loss: 1.3120\n",
      "Epoch [6/10], Step [300], Loss: 1.2113\n",
      "Epoch [6/10], Step [400], Loss: 1.1889\n",
      "Epoch [6/10], Step [500], Loss: 1.3870\n",
      "Epoch [6/10], Step [600], Loss: 1.0884\n",
      "Epoch [6/10], Step [700], Loss: 1.2323\n",
      "Epoch [6/10], Step [800], Loss: 1.1167\n",
      "Epoch [6/10], Step [900], Loss: 1.2100\n",
      "Epoch [7/10], Step [100], Loss: 1.4780\n",
      "Epoch [7/10], Step [200], Loss: 1.3918\n",
      "Epoch [7/10], Step [300], Loss: 1.2916\n",
      "Epoch [7/10], Step [400], Loss: 1.1644\n",
      "Epoch [7/10], Step [500], Loss: 1.2095\n",
      "Epoch [7/10], Step [600], Loss: 1.2862\n",
      "Epoch [7/10], Step [700], Loss: 1.2773\n",
      "Epoch [7/10], Step [800], Loss: 1.5146\n",
      "Epoch [7/10], Step [900], Loss: 1.2732\n",
      "Epoch [8/10], Step [100], Loss: 1.1229\n",
      "Epoch [8/10], Step [200], Loss: 1.6593\n",
      "Epoch [8/10], Step [300], Loss: 1.3995\n",
      "Epoch [8/10], Step [400], Loss: 1.0717\n",
      "Epoch [8/10], Step [500], Loss: 1.1002\n",
      "Epoch [8/10], Step [600], Loss: 1.5262\n",
      "Epoch [8/10], Step [700], Loss: 1.4214\n",
      "Epoch [8/10], Step [800], Loss: 1.3901\n",
      "Epoch [8/10], Step [900], Loss: 1.3105\n",
      "Epoch [9/10], Step [100], Loss: 1.2783\n",
      "Epoch [9/10], Step [200], Loss: 1.3076\n",
      "Epoch [9/10], Step [300], Loss: 1.4978\n",
      "Epoch [9/10], Step [400], Loss: 1.0474\n",
      "Epoch [9/10], Step [500], Loss: 1.2263\n",
      "Epoch [9/10], Step [600], Loss: 1.2561\n",
      "Epoch [9/10], Step [700], Loss: 1.1180\n",
      "Epoch [9/10], Step [800], Loss: 1.2328\n",
      "Epoch [9/10], Step [900], Loss: 1.3615\n",
      "Epoch [10/10], Step [100], Loss: 1.0238\n",
      "Epoch [10/10], Step [200], Loss: 1.2329\n",
      "Epoch [10/10], Step [300], Loss: 1.1608\n",
      "Epoch [10/10], Step [400], Loss: 1.0327\n",
      "Epoch [10/10], Step [500], Loss: 1.3290\n",
      "Epoch [10/10], Step [600], Loss: 1.3612\n",
      "Epoch [10/10], Step [700], Loss: 1.2082\n",
      "Epoch [10/10], Step [800], Loss: 1.3933\n",
      "Epoch [10/10], Step [900], Loss: 1.0616\n",
      "Accuracy of the network on the 10000 test images: 56.01 %\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_loader, test_loader)\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model/data/mlp_mnist.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_size, hidden_size, num_classes)\n",
    "model.load_state_dict(torch.load('model/data/mlp_mnist.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(images.reshape(-1, 784), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.autograd import Variable\n",
    "# mask = Variable(torch.bernoulli(input1.data.new(input1.data.size()).fill_(0.5)))\n",
    "# mask\n",
    "mask = torch.ones((10, 10))\n",
    "rate = 0.05\n",
    "mask.fill_(rate)\n",
    "mask_ = torch.bernoulli(mask)/rate\n",
    "mask_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
