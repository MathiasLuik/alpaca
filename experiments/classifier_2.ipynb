{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import softmax as softmax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader.builder import build_dataset\n",
    "from experiment_setup import build_estimator\n",
    "from uncertainty_estimator.masks import build_masks, DEFAULT_MASKS\n",
    "from analysis.metrics import uq_ndcg\n",
    "\n",
    "from model.cnn import SimpleConv, MediumConv, StrongConv\n",
    "from model.trainer import Trainer, EnsembleTrainer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_setups = {\n",
    "    'mnist': {\n",
    "        'model_class': SimpleConv,\n",
    "        'train_samples': 5000,\n",
    "        'epochs': 5,\n",
    "        'batch_size': 256,\n",
    "        'log_interval': 10,\n",
    "        'lr': 1e-2,\n",
    "        'num_classes': 10\n",
    "    },\n",
    "    'cifar_10': {\n",
    "        'model_class': StrongConv,\n",
    "        'train_samples': 45_000,\n",
    "        'epochs': 50,\n",
    "        'batch_size': 256,\n",
    "        'log_interval': 150,\n",
    "        'lr': 1e-2,\n",
    "        'num_classes': 9\n",
    "    }\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'use_cuda': True,\n",
    "    'seed': 1,\n",
    "    \n",
    "    'nn_runs': 150,\n",
    "    'patience': 6,\n",
    "    'dropout_uq': 0.5,\n",
    "    \n",
    "    'n_models': 10, \n",
    "    \n",
    "    # 'dataset': 'mnist',\n",
    "    'dataset': 'cifar_10',\n",
    "    \n",
    "    'model_runs': 3,\n",
    "    'repeat_runs': 3,\n",
    "}\n",
    "\n",
    "config.update(model_setups[config['dataset']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = build_dataset(config['dataset'], val_size=10_000)\n",
    "x_train, y_train = dataset.dataset('train')\n",
    "x_val, y_val = dataset.dataset('val')\n",
    "\n",
    "def cut_class(x, y, class_num):\n",
    "    new_x = x[np.where(y!=class_num)]\n",
    "    new_y = y[np.where(y!=class_num)]\n",
    "    ood = x[np.where(y==class_num)]\n",
    "    return new_x, new_y, ood\n",
    "\n",
    "if config['dataset'] == 'mnist':\n",
    "    ood = build_dataset('fashion_mnist', val_size=0)\n",
    "    x_ood, _ = ood.dataset('train') \n",
    "elif config['dataset'] == 'cifar_10':\n",
    "    x_train, y_train, x_ood = cut_class(x_train, y_train, '9')\n",
    "    x_val, y_val, _ = cut_class(x_val, y_val, '9')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_ood = scaler.transform(x_ood)\n",
    "\n",
    "# x_train /= 255.0\n",
    "# x_val /= 255.0\n",
    "# x_ood /= 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if config['dataset'] == 'mnist':\n",
    "    input_shape = (-1, 1, 28, 28)\n",
    "elif config['dataset'] == 'cifar_10':\n",
    "    input_shape = (-1, 3, 32, 32)\n",
    "x_train = x_train.reshape(input_shape)\n",
    "x_val = x_val.reshape(input_shape)\n",
    "x_ood = x_ood.reshape(input_shape)\n",
    "\n",
    "y_train = y_train.astype('long').reshape(-1)\n",
    "y_val = y_val.astype('long').reshape(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def retrain(\n",
    "        train_samples, n_models=config['n_models'], epochs=config['epochs'],\n",
    "        val_samples=2000, patience=config['patience']):\n",
    "    idxs = np.random.choice(len(x_train), train_samples, replace=False)\n",
    "    train_set = (x_train[idxs], y_train[idxs])\n",
    "    idxs = np.random.choice(len(x_val), val_samples, replace=False)\n",
    "    val_set = (x_val[idxs], y_val[idxs]) \n",
    "    \n",
    "    model_class = config['model_class'] \n",
    "    model = model_class()\n",
    "    print(model)\n",
    "    trainer = Trainer(model)\n",
    "    print(train_set[0].shape)\n",
    "    trainer.fit(\n",
    "        train_set, val_set , epochs=epochs, verbose=True, patience=patience)\n",
    "\n",
    "    ensemble = EnsembleTrainer(model_class, {}, n_models)\n",
    "    \n",
    "    return trainer, ensemble\n",
    "\n",
    "unique, counts = np.unique(y_train[:config['train_samples']], return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer, ensemble = retrain(config['train_samples'], n_models=config['n_models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Model accuracy train', accuracy_score(y_train[:3000], trainer.predict(x_train[:3000])))\n",
    "print('Model accuracy val', accuracy_score(y_val[:3000], trainer.predict(x_val[:3000])))\n",
    "print('Ensemble accuracy', accuracy_score(y_val[:3000], ensemble.predict(x_val[:3000])))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
